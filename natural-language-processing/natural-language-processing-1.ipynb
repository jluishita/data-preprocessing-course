{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Lenguaje Natural\n",
    "\n",
    "En este notebook veremos dos técnicas básicas, aunque en muchos casos eficientes, para codificar la información contenida en los textos que queremos analizar. Estas técnicas se conocen como bolsa de palabras (o Bag-of-words) y TF-IDF (acrónimo de Term Frequency-Inverse Document Frequency).\n",
    "\n",
    "Para probar los resultados, utilizaremos el conjunto de datos sobre las opiniones expresadas en la web Rotten Tomatoes, que podemos obtener en este link:\n",
    "\n",
    "https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el paquete Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de las críticas en Rotten Tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rotten_tomatoes_critic_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Andrew L. Urban</td>\n",
       "      <td>False</td>\n",
       "      <td>Urban Cinefile</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Louise Keller</td>\n",
       "      <td>False</td>\n",
       "      <td>Urban Cinefile</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>FILMINK (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5/5</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ethan Alter</td>\n",
       "      <td>True</td>\n",
       "      <td>Hollywood Reporter</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>What's really lacking in The Lightning Thief i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130012</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>Chuck O'Leary</td>\n",
       "      <td>False</td>\n",
       "      <td>Fantastica Daily</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2005-11-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130013</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>Ken Hanke</td>\n",
       "      <td>False</td>\n",
       "      <td>Mountain Xpress (Asheville, NC)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5/5</td>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>Seen today, it's not only a startling indictme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130014</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>Dennis Schwartz</td>\n",
       "      <td>False</td>\n",
       "      <td>Dennis Schwartz Movie Reviews</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>B+</td>\n",
       "      <td>2010-09-16</td>\n",
       "      <td>A rousing visual spectacle that's a prequel of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130015</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>Christopher Lloyd</td>\n",
       "      <td>False</td>\n",
       "      <td>Sarasota Herald-Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>3.5/5</td>\n",
       "      <td>2011-02-28</td>\n",
       "      <td>A simple two-act story: Prelude to war, and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130016</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>Brent McKnight</td>\n",
       "      <td>False</td>\n",
       "      <td>The Last Thing I See</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>Rides the line between being a pure artifact o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1130017 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rotten_tomatoes_link        critic_name  top_critic  \\\n",
       "0                  m/0814255    Andrew L. Urban       False   \n",
       "1                  m/0814255      Louise Keller       False   \n",
       "2                  m/0814255                NaN       False   \n",
       "3                  m/0814255       Ben McEachen       False   \n",
       "4                  m/0814255        Ethan Alter        True   \n",
       "...                      ...                ...         ...   \n",
       "1130012          m/zulu_dawn      Chuck O'Leary       False   \n",
       "1130013          m/zulu_dawn          Ken Hanke       False   \n",
       "1130014          m/zulu_dawn    Dennis Schwartz       False   \n",
       "1130015          m/zulu_dawn  Christopher Lloyd       False   \n",
       "1130016          m/zulu_dawn     Brent McKnight       False   \n",
       "\n",
       "                          publisher_name review_type review_score review_date  \\\n",
       "0                         Urban Cinefile       Fresh          NaN  2010-02-06   \n",
       "1                         Urban Cinefile       Fresh          NaN  2010-02-06   \n",
       "2                    FILMINK (Australia)       Fresh          NaN  2010-02-09   \n",
       "3                Sunday Mail (Australia)       Fresh        3.5/5  2010-02-09   \n",
       "4                     Hollywood Reporter      Rotten          NaN  2010-02-10   \n",
       "...                                  ...         ...          ...         ...   \n",
       "1130012                 Fantastica Daily      Rotten          2/5  2005-11-02   \n",
       "1130013  Mountain Xpress (Asheville, NC)       Fresh        3.5/5  2007-03-07   \n",
       "1130014    Dennis Schwartz Movie Reviews       Fresh           B+  2010-09-16   \n",
       "1130015          Sarasota Herald-Tribune      Rotten        3.5/5  2011-02-28   \n",
       "1130016             The Last Thing I See      Rotten            C  2020-07-09   \n",
       "\n",
       "                                            review_content  \n",
       "0        A fantasy adventure that fuses Greek mythology...  \n",
       "1        Uma Thurman as Medusa, the gorgon with a coiff...  \n",
       "2        With a top-notch cast and dazzling special eff...  \n",
       "3        Whether audiences will get behind The Lightnin...  \n",
       "4        What's really lacking in The Lightning Thief i...  \n",
       "...                                                    ...  \n",
       "1130012                                                NaN  \n",
       "1130013  Seen today, it's not only a startling indictme...  \n",
       "1130014  A rousing visual spectacle that's a prequel of...  \n",
       "1130015  A simple two-act story: Prelude to war, and th...  \n",
       "1130016  Rides the line between being a pure artifact o...  \n",
       "\n",
       "[1130017 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no hay valores faltantes en la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fresh     720210\n",
       "Rotten    409807\n",
       "Name: review_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una variable target de forma que valga 1 si la crítica es positiva y 0 si es negativa. Después, redefinimos el DataFrame de forma que sólo contenga 'review_content' y 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['review_type'].apply(lambda x: 1 if x=='Fresh' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review_content', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fantasy adventure that fuses Greek mythology...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uma Thurman as Medusa, the gorgon with a coiff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a top-notch cast and dazzling special eff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's really lacking in The Lightning Thief i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130013</th>\n",
       "      <td>Seen today, it's not only a startling indictme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130014</th>\n",
       "      <td>A rousing visual spectacle that's a prequel of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130015</th>\n",
       "      <td>A simple two-act story: Prelude to war, and th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130016</th>\n",
       "      <td>Rides the line between being a pure artifact o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1130017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_content  target\n",
       "0        A fantasy adventure that fuses Greek mythology...       1\n",
       "1        Uma Thurman as Medusa, the gorgon with a coiff...       1\n",
       "2        With a top-notch cast and dazzling special eff...       1\n",
       "3        Whether audiences will get behind The Lightnin...       1\n",
       "4        What's really lacking in The Lightning Thief i...       0\n",
       "...                                                    ...     ...\n",
       "1130012                                                NaN       0\n",
       "1130013  Seen today, it's not only a startling indictme...       1\n",
       "1130014  A rousing visual spectacle that's a prequel of...       1\n",
       "1130015  A simple two-act story: Prelude to war, and th...       0\n",
       "1130016  Rides the line between being a pure artifact o...       0\n",
       "\n",
       "[1130017 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las instancias para las que no haya crítica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A fantasy adventure that fuses Greek mythology to contemporary American places and values. Anyone around 15 (give or take a couple of years) will thrill to the visual spectacle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_content'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el metodo train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dos Series de Pandas, una llamada X que contiene el texto de las críticas y otra llamada y que contiene la variable target. En otras ocasiones hemos hecho algo parecido, solo que X era un DataFrame. Aquí necesitaremos que sea una Serie para que CountVectorizer lo entienda correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review_content']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744947"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 0\n",
    "X = 0\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la clase CountVectorizer. CountVectorizer nos servirá para construir la Bag of Words o Bolsa de Palabras del conjunto de textos que queremos analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la matriz en la que las filas representan los distintos textos del corpus y las columnas representan las palabras seleccionadas por CountVectorizer para cumplir la función de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_token = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '13', ..., 'yourself', 'youth', 'zombie'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos Pipeline y un método de clasificación como LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos un Pipeline en el que el primer paso sea crear la Bag of Words con COuntVectorizer y el segundo sea aplicar el modelo de clasificación (en este caso, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vectorizer', CountVectorizer(max_features=2000)),\n",
    "                     ('model', LogisticRegression(max_iter=200))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(max_features=2000)),\n",
       "                ('model', LogisticRegression(max_iter=200))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la predicción sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la predicción sobre el conjunto de test usando accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7638926406312965"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver qué palabras influyen más positivamente o negativamente en la clasificación de los textos utilizando los coeficientes de la regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pipeline.named_steps['model'].coef_\n",
    "names = pipeline.named_steps['vectorizer'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame({'words':names, 'coeff':features[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ordenar los pesos de mayor a menor, podemos ver que las palabras que más influyen a la hora de clasificar una review como positiva son palabras con significado positivo, como \"refrescante\" o \"encantador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>gem</td>\n",
       "      <td>2.315051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>refreshingly</td>\n",
       "      <td>2.088166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>refreshing</td>\n",
       "      <td>1.954085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>delightful</td>\n",
       "      <td>1.944456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>wonderfully</td>\n",
       "      <td>1.885329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>superbly</td>\n",
       "      <td>1.850268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>exhilarating</td>\n",
       "      <td>1.823960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>superb</td>\n",
       "      <td>1.726159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>1.723899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>absorbing</td>\n",
       "      <td>1.699100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>riveting</td>\n",
       "      <td>1.683486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>masterpiece</td>\n",
       "      <td>1.677503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>brilliantly</td>\n",
       "      <td>1.672530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>mesmerizing</td>\n",
       "      <td>1.666076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>blast</td>\n",
       "      <td>1.650194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>heartbreaking</td>\n",
       "      <td>1.641082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>shines</td>\n",
       "      <td>1.616625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>1.610685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>rewarding</td>\n",
       "      <td>1.598261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>devastating</td>\n",
       "      <td>1.565610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words     coeff\n",
       "715             gem  2.315051\n",
       "1389   refreshingly  2.088166\n",
       "1388     refreshing  1.954085\n",
       "422      delightful  1.944456\n",
       "1966    wonderfully  1.885329\n",
       "1674       superbly  1.850268\n",
       "577    exhilarating  1.823960\n",
       "1673         superb  1.726159\n",
       "1221    outstanding  1.723899\n",
       "15        absorbing  1.699100\n",
       "1426       riveting  1.683486\n",
       "1059    masterpiece  1.677503\n",
       "211     brilliantly  1.672530\n",
       "1085    mesmerizing  1.666076\n",
       "179           blast  1.650194\n",
       "800   heartbreaking  1.641082\n",
       "1521         shines  1.616625\n",
       "537       enjoyable  1.610685\n",
       "1417      rewarding  1.598261\n",
       "443     devastating  1.565610"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs.sort_values(by='coeff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ordenar los coeficientes de menor a mayor, vemos que las palabras que tienen más relevancia al clasificar una crítica como negativa son palabras con significado negativo como \"desperdicio\" o \"vago\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>sadly</td>\n",
       "      <td>-1.680110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>waste</td>\n",
       "      <td>-1.718685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>lazy</td>\n",
       "      <td>-1.720419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>hollow</td>\n",
       "      <td>-1.727594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>-1.795773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>boring</td>\n",
       "      <td>-1.801279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>mediocre</td>\n",
       "      <td>-1.854898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>-1.895236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>worst</td>\n",
       "      <td>-1.952202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>dull</td>\n",
       "      <td>-1.974625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>pointless</td>\n",
       "      <td>-2.013786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>fails</td>\n",
       "      <td>-2.083972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>bore</td>\n",
       "      <td>-2.146653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>bland</td>\n",
       "      <td>-2.176101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-2.232095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>lame</td>\n",
       "      <td>-2.266475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>uninspired</td>\n",
       "      <td>-2.430169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>tedious</td>\n",
       "      <td>-2.441369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-2.503007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>unfunny</td>\n",
       "      <td>-3.348155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words     coeff\n",
       "1449           sadly -1.680110\n",
       "1908           waste -1.718685\n",
       "974             lazy -1.720419\n",
       "832           hollow -1.727594\n",
       "462   disappointment -1.795773\n",
       "195           boring -1.801279\n",
       "1075        mediocre -1.854898\n",
       "461    disappointing -1.895236\n",
       "1976           worst -1.952202\n",
       "492             dull -1.974625\n",
       "1290       pointless -2.013786\n",
       "598            fails -2.083972\n",
       "193             bore -2.146653\n",
       "178            bland -2.176101\n",
       "1843   unfortunately -2.232095\n",
       "957             lame -2.266475\n",
       "1845      uninspired -2.430169\n",
       "1714         tedious -2.441369\n",
       "1296          poorly -2.503007\n",
       "1844         unfunny -3.348155"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs.sort_values(by='coeff', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar ahora a sustituir la técnica de Bag of Words con otra conocida como TF-IDF (de term frequency-inverse document frequency). Esta técnica no sólo tiene en cuenta cuántas veces se repite una palabra en un documento sino también cuántos documentos dentro del corpus contienen la misma palabra. De esta forma, podemos restar importancia a palabras que aparezcan en todos los documentos del corpus.\n",
    "\n",
    "Importamos TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un Pipeline donde el primer paso sea el TfidfVectorizer y el segundo un modelo de clasificación. En este caso, una regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vectorizer', TfidfVectorizer(max_features=3000)),\n",
    "                     ('model', LogisticRegression(max_iter=200))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(max_features=3000)),\n",
       "                ('model', LogisticRegression(max_iter=200))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la predicción del Pipeline sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782978553810319"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el caso anterior, analizamos los coeficientes de la regresión logística para detectar las palabras que tienen más relevancia para clasificar una crítica como positiva o negativa.\n",
    "\n",
    "Como en el caso anterior, vemos que las palabras positivas están asociadas a críticas positivas y las negativas a críticas negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pipeline.named_steps['model'].coef_[0]\n",
    "names = pipeline.named_steps['vectorizer'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame({'words':names, 'coeff':features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>5.346007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>refreshing</td>\n",
       "      <td>5.256345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>deftly</td>\n",
       "      <td>5.184255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>delightful</td>\n",
       "      <td>4.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>gem</td>\n",
       "      <td>4.942441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>entertaining</td>\n",
       "      <td>4.857087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>4.755440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>masterpiece</td>\n",
       "      <td>4.688854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>refreshingly</td>\n",
       "      <td>4.669015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>wonderfully</td>\n",
       "      <td>4.615484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>superb</td>\n",
       "      <td>4.595584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>powerful</td>\n",
       "      <td>4.574437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>exhilarating</td>\n",
       "      <td>4.450775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>riveting</td>\n",
       "      <td>4.383117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>brilliantly</td>\n",
       "      <td>4.297575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>rare</td>\n",
       "      <td>4.288006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>superbly</td>\n",
       "      <td>4.227227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>delightfully</td>\n",
       "      <td>4.224958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>fun</td>\n",
       "      <td>4.190466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>touching</td>\n",
       "      <td>4.118130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words     coeff\n",
       "854      enjoyable  5.346007\n",
       "2125    refreshing  5.256345\n",
       "667         deftly  5.184255\n",
       "674     delightful  4.998324\n",
       "1109           gem  4.942441\n",
       "860   entertaining  4.857087\n",
       "334      brilliant  4.755440\n",
       "1632   masterpiece  4.688854\n",
       "2126  refreshingly  4.669015\n",
       "2956   wonderfully  4.615484\n",
       "2565        superb  4.595584\n",
       "1997      powerful  4.574437\n",
       "907   exhilarating  4.450775\n",
       "2191      riveting  4.383117\n",
       "335    brilliantly  4.297575\n",
       "2092          rare  4.288006\n",
       "2566      superbly  4.227227\n",
       "675   delightfully  4.224958\n",
       "1093           fun  4.190466\n",
       "2716      touching  4.118130"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs.sort_values(by='coeff', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>boring</td>\n",
       "      <td>-4.679583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>mediocre</td>\n",
       "      <td>-4.701441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>pointless</td>\n",
       "      <td>-4.701675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>unconvincing</td>\n",
       "      <td>-4.822999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>bore</td>\n",
       "      <td>-4.912132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>-4.943325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>tiresome</td>\n",
       "      <td>-5.062235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>alas</td>\n",
       "      <td>-5.228148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>lame</td>\n",
       "      <td>-5.307337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>dull</td>\n",
       "      <td>-5.486565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>uninspired</td>\n",
       "      <td>-5.501160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>lifeless</td>\n",
       "      <td>-5.762984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-5.960412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>bland</td>\n",
       "      <td>-5.980625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>worst</td>\n",
       "      <td>-6.027401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>tedious</td>\n",
       "      <td>-6.172948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>misfire</td>\n",
       "      <td>-6.348615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>fails</td>\n",
       "      <td>-6.367298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-6.532164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>unfunny</td>\n",
       "      <td>-7.584826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words     coeff\n",
       "310          boring -4.679583\n",
       "1654       mediocre -4.701441\n",
       "1971      pointless -4.701675\n",
       "2784   unconvincing -4.822999\n",
       "308            bore -4.912132\n",
       "732   disappointing -4.943325\n",
       "2697       tiresome -5.062235\n",
       "89             alas -5.228148\n",
       "1486           lame -5.307337\n",
       "788            dull -5.486565\n",
       "2803     uninspired -5.501160\n",
       "1538       lifeless -5.762984\n",
       "1979         poorly -5.960412\n",
       "285           bland -5.980625\n",
       "2968          worst -6.027401\n",
       "2617        tedious -6.172948\n",
       "1697        misfire -6.348615\n",
       "946           fails -6.367298\n",
       "2801  unfortunately -6.532164\n",
       "2802        unfunny -7.584826"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs.sort_values(by='coeff', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como comprobación adicional, podemos ver las palabras que tienen menos relevancia a la hora de clasificar una crítica. Para ello, vemos las palabras que tienen los valores absolutos de los coeficientes de la regresión logística más bajos. Vemos que entre esas palabras hay algunas que no nos permiten saber si la crítica es en realidad positiva o negativa, como \"arma\" o \"niños\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeffs['abs'] = df_coeffs['coeff'].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coeff</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>gun</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>standing</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>struggle</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>cop</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>children</td>\n",
       "      <td>-0.001669</td>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>joe</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>celebrity</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.002005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>religious</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>taste</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>par</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.003279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>military</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>rarely</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>treats</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.004994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>be</td>\n",
       "      <td>-0.005182</td>\n",
       "      <td>0.005182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>devil</td>\n",
       "      <td>-0.005609</td>\n",
       "      <td>0.005609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>means</td>\n",
       "      <td>-0.006751</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>following</td>\n",
       "      <td>-0.008650</td>\n",
       "      <td>0.008650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>knight</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.008792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>quite</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.009129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>pride</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.009496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>hill</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>0.010165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>friend</td>\n",
       "      <td>-0.010186</td>\n",
       "      <td>0.010186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>fairy</td>\n",
       "      <td>-0.010331</td>\n",
       "      <td>0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>context</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>0.011175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>whenever</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.011177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>racial</td>\n",
       "      <td>-0.011342</td>\n",
       "      <td>0.011342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>golden</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0.011562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3d</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.011698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>child</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>0.012562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>headed</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>taylor</td>\n",
       "      <td>-0.013503</td>\n",
       "      <td>0.013503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>grab</td>\n",
       "      <td>-0.013569</td>\n",
       "      <td>0.013569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>alien</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.013799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>zombie</td>\n",
       "      <td>-0.013909</td>\n",
       "      <td>0.013909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>ring</td>\n",
       "      <td>0.014643</td>\n",
       "      <td>0.014643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>mr</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.016604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>totally</td>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.016967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>hours</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.017167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>several</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.017591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words     coeff       abs\n",
       "1194        gun -0.000265  0.000265\n",
       "2472   standing  0.000318  0.000318\n",
       "2528   struggle  0.000629  0.000629\n",
       "565         cop  0.000831  0.000831\n",
       "448    children -0.001669  0.001669\n",
       "1438        joe  0.001913  0.001913\n",
       "410   celebrity  0.002005  0.002005\n",
       "2139  religious  0.002913  0.002913\n",
       "2608      taste  0.003024  0.003024\n",
       "1889        par  0.003279  0.003279\n",
       "1686   military  0.004418  0.004418\n",
       "2093     rarely  0.004866  0.004866\n",
       "2737     treats  0.004994  0.004994\n",
       "234          be -0.005182  0.005182\n",
       "711       devil -0.005609  0.005609\n",
       "1650      means -0.006751  0.006751\n",
       "1050  following -0.008650  0.008650\n",
       "1473     knight  0.008792  0.008792\n",
       "2082      quite  0.009129  0.009129\n",
       "2019      pride  0.009496  0.009496\n",
       "1271       hill  0.010165  0.010165\n",
       "1083     friend -0.010186  0.010186\n",
       "2541    subject  0.010316  0.010316\n",
       "950       fairy -0.010331  0.010331\n",
       "551     context  0.011175  0.011175\n",
       "2912   whenever  0.011177  0.011177\n",
       "2084     racial -0.011342  0.011342\n",
       "1151     golden -0.011562  0.011562\n",
       "11           3d  0.011698  0.011698\n",
       "446       child  0.012562  0.012562\n",
       "1237     headed  0.012737  0.012737\n",
       "2610     taylor -0.013503  0.013503\n",
       "1162       grab -0.013569  0.013569\n",
       "92        alien  0.013799  0.013799\n",
       "2998     zombie -0.013909  0.013909\n",
       "2184       ring  0.014643  0.014643\n",
       "1738         mr  0.016604  0.016604\n",
       "2713    totally  0.016967  0.016967\n",
       "1309      hours  0.017167  0.017167\n",
       "2317    several  0.017591  0.017591"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs.sort_values(by='abs').head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
